{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d24c04b0-151f-4b83-bfc6-cb337bb9ad62",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-size: 40px;\">\n",
    "Perdicting NBA Outcomes from Statistics\n",
    "</div>\n",
    "<div style=\"text-align: center; font-size: 30px;\">\n",
    "Kyle Beedon\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28230bde-4590-419c-8c43-f5f6dc1281fa",
   "metadata": {},
   "source": [
    "## **Abstract**: \n",
    "WRITE after data collection is fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2abb7a0-bcf7-43c1-8c50-64e702934839",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, StratifiedKFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from scipy.stats import randint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c300774-9789-4ba1-b407-b3cc1a408e59",
   "metadata": {},
   "source": [
    "## **1. Introduction**:\n",
    "The National Basketball Association (NBA) generates significant annual revenues and has a passionate fanbase. With 30 teams playing 82 games each season, fans and analysts are keen to predict game outcomes, especially for betting purposes. An effective model that could accurately predict game outcomes could provide fans with an edge over the sports betting industry.\n",
    "\n",
    "Each NBA game typically has a favorite, whether it’s the home team, the team with a better record, or a team dealing with less injuries. Key factors influencing predictions are team dynamics and player availability, but the most crucial aspect is a team's recent statistical performance. Recent performance can uncover trends that influence game outcomes. A model would need to be more than 60% accurate to be considered reliable, as favorites typically win 60% of the time on average.\n",
    "\n",
    "To gather data, I used Python to automate web scraping from basketball-reference.com, a reliable source offering detailed data from every NBA game since the 1940s. This data was loaded into R and manipulated using dplyr and tidyverse for efficiency. The dataset focused on recent statistics, excluding outdated data that could skew predictions, such as pre-three-point era stats. It included 10,748 games from 2016 onward, with data on every team, the game outcome, and recorded statistics.\n",
    "\n",
    "Key metrics for analysis included Offensive and Defensive Ratings, Field Goal Percentage (FG%), Three-Point Percentage (3P%), Free Throw Percentage (FT%), Turnover Percentage (Turnover %), and Offensive Rebound Percentage (ORB%). The final dataset treated each season as a fresh start, using previous game averages to predict future outcomes. **For early games, season averages from the previous year were used, while later games relied on averages from the most recent n games, joined by the gameID for comparison.** (TAKE OUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4dc53b-2ea2-4415-be49-d47e38787fc1",
   "metadata": {},
   "source": [
    "## **2. Literature Review**:\n",
    "For this project, I will implement a train-test split for all the box scores and standardize the data. I will then train several different models, including logistic regression, random forest classifier, and support vector classifier (SVM).\n",
    "\n",
    "Logistic regression is the simplest of these models, designed to predict a binary outcome (such as win or loss) using a decision boundary at 0.5. A random forest is an ensemble of decision trees, where each tree is trained on a random subset of the data and features. This reduces overfitting by averaging the predictions of many trees, which enhances accuracy and generalization. The support vector classifier (SVM) works by finding a hyperplane that best separates the data into different classes. It is effective for high-dimensional data and can handle complex relationships by using kernel functions to transform the data into higher dimensions.\n",
    "\n",
    "These three models—logistic regression, random forest, and SVM—are particularly suitable for our data, as they can handle both linear and non-linear relationships, manage large feature spaces, and offer various ways to improve accuracy, making them versatile for predicting NBA game outcomes based on box score statistics.\n",
    "\n",
    "Once the models are trained, we will assess their efficiency using various metrics. A confusion matrix will help visualize the number of false positives, false negatives, true positives, and true negatives. This, along with standard model accuracy, will provide insight into model performance. Additionally, the matrix will allow us to evaluate other important metrics such as precision, recall, and F1 score.\n",
    "\n",
    "In examining similar projects that predict NBA outcomes, different methodologies and model accuracies have been explored, but several key approaches remain consistent.\n",
    "\n",
    "Matthew Houde’s thesis applies the CRISP-DM methodology to predict NBA game outcomes. He scrapes data from nba.com, extracting key statistics such as win percentage, field goal percentage, and advanced metrics like offensive rating and true shooting percentage. After cleaning and organizing the data, he performs exploratory data analysis (EDA) to identify influential features. Houde then engineers additional features, including team Elo rating and recent performance, and splits the dataset for training and testing. He evaluates six machine learning models (logistic regression, random forest classifier, k-nearest neighbors classifier, support vector classifier, Gaussian Naive Bayes, and XGBoost classifier) to predict game outcomes. His Gaussian Naive Bayes model achieved the highest accuracy of 65.1%. He used data from the 2018-2021 seasons and employed an Elo rating system based on the last 10 games and win percentage. All other statistics were based on teams’ averages for the season prior to each game. The Elo score started at a median of 1500 and was adjusted based on factors such as upsets and home victories.\n",
    "\n",
    "Josh Weiner scraped player and team data from Synergy Sports and combined it into two large dataframes. For feature engineering, he implemented an Elo rating similar to Houde’s, but with a distinction: not all wins were given equal weight. For instance, a win against a weaker team had less impact on the Elo rating compared to an upset or road win. He also implemented a method using stats from the last 10 games (similar to Houde’s work). Additionally, Weiner created features based on recent player performance and season-long performance, including player efficiency ratings. He used an 80:20 train-test split, applied logistic regression, and initially achieved a testing accuracy of 66.95%. After cross-validation, he implemented a random forest classifier, achieving the same initial accuracy of 66.95%. After performing a randomized search for hyperparameter tuning, his model’s accuracy improved to 67.15%.\n",
    "\n",
    "There are several algorithms to choose from, and based on past projects, we would consider any model with an accuracy above 65% as successful. Models predicting NBA outcomes with accuracy above 70% are considered exceptional, while an accuracy in the 60-65% range is generally acceptable. Now, let's dive into the methodology used in this project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969dbe93-80b4-47ea-aac4-96fa1bfb4ad2",
   "metadata": {},
   "source": [
    "## **3. Methodology**:\n",
    "In this section, we will walk through the step-by-step process of this project, including feature selection, model building, result interpretation, and analysis.\n",
    "\n",
    "### a) Data Selection:\n",
    "Choosing the value of n was a significant consideration in this project. **The parameter n defines the number of games for which all features reflect the mean statistics from the previous season. While this approach is not ideal, it becomes necessary when there aren’t enough games in the current season to assess a team’s consistent performance accurately.** (TAKE OUT)\n",
    "\n",
    "I experimented with different values of n, ranging from 5 to 25, and evaluated the accuracy of a logistic regression model for each. Ultimately, the value of n that yielded the best performance was 15.\n",
    "\n",
    "**This means the dataset will use averages from each team’s last 15 games.** For games occurring before the 15th game of the season, the features will default to the mean statistics from the previous season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2821ac70-38f4-4f7f-b853-d33f47870c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#box_scores = pd.read_csv(\"DATA/box_scores_using_szn/FINAL_boxscores_dataset.csv\")\n",
    "box_scores = pd.read_csv(\"DATA/Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9a9ce199-b7ba-4e29-afa8-e8f579ae0f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['season', 'date', 'team.x', 'game_number.x', 'home.x', 'result',\n",
      "       'back_to_back.x', 'eFG%.x', 'FT%.x', 'ORB%.x', 'DRB%.x', 'NET_rating.x',\n",
      "       'win%.x', 'team.y', 'game_number.y', 'back_to_back.y', 'eFG%.y',\n",
      "       'FT%.y', 'ORB%.y', 'DRB%.y', 'NET_rating.y', 'win%.y'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(box_scores.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0ae4c9de-4d7d-4cd4-8fc3-b2df14d4bd82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  team.x  game_number.x  home.x result  back_to_back.x    eFG%.x      FT%.x  \\\n",
      "0    ATL              1       1      L               0  0.526944  77.752161   \n",
      "1    CHI              1       1      W               0  0.488966  78.277697   \n",
      "2    GSW              1       1      W               0  0.539653  76.828555   \n",
      "3    BOS              1       1      W               0  0.488559  75.446961   \n",
      "4    BRK              1       1      L               0  0.490814  74.793616   \n",
      "\n",
      "   ORB%.x  DRB%.x  NET_rating.x    win%.x team.y  game_number.y  \\\n",
      "0  21.369  73.363      5.762601  0.731707    DET              1   \n",
      "1  26.961  74.354      3.200949  0.609756    CLE              1   \n",
      "2  24.076  74.504     10.249311  0.817073    NOP              1   \n",
      "3  24.715  75.042      0.163742  0.487805    PHI              1   \n",
      "4  23.865  73.709     -3.064797  0.463415    CHI              2   \n",
      "\n",
      "   back_to_back.y    eFG%.y      FT%.y  ORB%.y  DRB%.y  NET_rating.y    win%.y  \n",
      "0               0  0.482026  70.293798  27.724  74.993     -1.069369  0.390244  \n",
      "1               0  0.519662  75.129266  26.810  74.693      4.822486  0.646341  \n",
      "2               0  0.500515  75.139665  27.077  75.079      0.863273  0.548780  \n",
      "3               0  0.459053  67.588326  25.529  72.957     -9.315684  0.219512  \n",
      "4               1  0.465517  69.565217  15.217  78.431      2.000652  1.000000  \n",
      "team.x            0\n",
      "game_number.x     0\n",
      "home.x            0\n",
      "result            0\n",
      "back_to_back.x    0\n",
      "eFG%.x            0\n",
      "FT%.x             0\n",
      "ORB%.x            0\n",
      "DRB%.x            0\n",
      "NET_rating.x      0\n",
      "win%.x            0\n",
      "team.y            0\n",
      "game_number.y     0\n",
      "back_to_back.y    0\n",
      "eFG%.y            0\n",
      "FT%.y             0\n",
      "ORB%.y            0\n",
      "DRB%.y            0\n",
      "NET_rating.y      0\n",
      "win%.y            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "irrelevant_columns = [\"season\", \"date\"]\n",
    "#    \"gameId\",\"team.x\", \"Date.x\", \n",
    "#    \"team.y\", \"game_number.y\", \"outcome.y\"\n",
    "\n",
    "# Drop irrelevant columns for model building\n",
    "data = box_scores.drop(columns=irrelevant_columns)\n",
    "\n",
    "#print(data.head())\n",
    "# print(box_scores.isnull().sum()) # There are 0 null value in this dataset\n",
    "print(data.head())\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805693a8-e121-4b41-8c7a-57205c10531d",
   "metadata": {},
   "source": [
    "Our focus is on outcome.x as the response variable, which is why we exclude outcome.y. Additionally, we drop all non-numerical features that do not contribute meaningful information. For instance, we assume that the date and season have no impact on determining the outcome of a given game. Similarly, we avoid encoding team names, as the model is designed to remain objective and blind to team identities. Instead, the emphasis is placed entirely on a team’s recent performance and, **for games within the first 15 of a season, the performance from the previous season.** (TAKE out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247908e9-d94b-4f8b-b244-7caa9c460f55",
   "metadata": {},
   "source": [
    "### b) Train-Test-Split and Standardization\n",
    "\n",
    "Next, we create the training and testing datasets using an 80/20 split. The target variable, outcome.x, is separated from the feature dataset X and stored in y. To ensure consistent scaling across all numerical features, we standardize them using the StandardScaler from sklearn.preprocessing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4d706cb3-2dce-449b-b50e-4250b991e86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'result' column to get features\n",
    "X = data.drop(columns=['result'])\n",
    "\n",
    "# Keep only 'game_number.x' and 'game_number.y' unscaled\n",
    "unscaled_feature = X[['game_number.x', 'game_number.y']]\n",
    "\n",
    "# Drop unscaled and unwanted features from those to scale\n",
    "features_to_scale = X.drop(columns=['game_number.x', 'game_number.y', 'team.x', 'team.y'])\n",
    "\n",
    "# Standardize the remaining features\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features_to_scale)\n",
    "\n",
    "# Reconstruct a DataFrame from scaled features\n",
    "X_standardized_df = pd.DataFrame(scaled_features, columns=features_to_scale.columns)\n",
    "\n",
    "# Add back only the game_number columns (not team.x / team.y)\n",
    "X_standardized_df[['game_number.x', 'game_number.y']] = unscaled_feature.reset_index(drop=True)\n",
    "\n",
    "# Define the target variable\n",
    "y = data['result']\n",
    "\n",
    "# Train-test split (80-20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_standardized_df, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573aa8a5-a76c-4908-ac12-bcebdb7e3b68",
   "metadata": {},
   "source": [
    "### c) Logistic regression model\n",
    "\n",
    "Now we fit a logistic regression model. We begin by applying Recursive Feature Elimination (RFE) for feature selection, identifying the most impactful features. Using the dataset with the selected features, we train the model, evaluate its performance on the test data, and analyze the results.\n",
    "\n",
    "After running the model multiple times with different values for the number of features to select, I found that selecting 11 features yielded the highest improvement in model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e16189a6-253d-4f4f-9650-9444da35c286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fit logistic regression model on training data\n",
    "model = LogisticRegression(max_iter=10000)\n",
    "\n",
    "# Recursive Feature Elimination (RFE) for feature selection\n",
    "selector = RFE(model, n_features_to_select=11)  # 11 features maximizes model success\n",
    "X_train_rfe = selector.fit_transform(X_train, y_train)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train_rfe, y_train)\n",
    "\n",
    "# Find model coefficients for the selected features\n",
    "selected_features = X_train.columns[selector.support_]  # Get the selected features\n",
    "coefficients = pd.DataFrame(model.coef_[0], selected_features, columns=['Coefficient'])\n",
    "\n",
    "# Visualize the coefficients for the selected features\n",
    "plt.figure(figsize=(10, 6))\n",
    "coefficients['Coefficient'].sort_values().plot(kind='barh')\n",
    "plt.xlabel('Coefficient Value')\n",
    "plt.title('Feature Importance Based on Logistic Regression Coefficients (After RFE)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82316b2d-f1ae-41ab-b2ee-f105b2b1e820",
   "metadata": {},
   "source": [
    "In this graph, we can observe the features selected by RFE. The features with the highest positive coefficients include home.x, off_rating.x, count_w.x, def_rating.y, and back_to_back.y, indicating that these factors strongly contribute to a positive prediction for the .x team. Conversely, features with the most negative coefficients include back_to_back.x, opp_3p%.y, off_rating.y, def_rating.x, and count_w.y, suggesting a negative impact on the likelihood of the .x team winning.\n",
    "\n",
    "Our target variable is outcome.x, meaning we are predicting whether the .x team will win. If the target variable were switched to outcome.y, we would expect the signs of these coefficients to flip entirely.\n",
    "\n",
    "The selected features reveal several insights: the home advantage (home.x) plays a crucial role, recent success in games (count_w) significantly influences predictions, and whether a team is rested, as indicated by the back_to_back variable, also holds importance. Additionally, the most critical statistics appear to be off_rating and def_rating, highlighting the significance of offensive and defensive efficiency in predicting game outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b4387e6c-9822-49e9-b062-f55b1dfb51bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kylebeedon/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.6407\n",
      "\n",
      "Confusion Matrix:\n",
      "[[711 446]\n",
      " [415 824]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           L       0.63      0.61      0.62      1157\n",
      "           W       0.65      0.67      0.66      1239\n",
      "\n",
      "    accuracy                           0.64      2396\n",
      "   macro avg       0.64      0.64      0.64      2396\n",
      "weighted avg       0.64      0.64      0.64      2396\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Pandas data cast to numpy dtype of object. Check input data with np.asarray(data).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Statistical Summary (using Statsmodels Logit for p-values)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Add constant to the features (intercept)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m X_train_const \u001b[38;5;241m=\u001b[39m sm\u001b[38;5;241m.\u001b[39madd_constant(X_train_rfe)  \u001b[38;5;66;03m# Add intercept for statsmodels\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m logit_model \u001b[38;5;241m=\u001b[39m \u001b[43msm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLogit\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_const\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Fit the model\u001b[39;00m\n\u001b[1;32m     20\u001b[0m result \u001b[38;5;241m=\u001b[39m logit_model\u001b[38;5;241m.\u001b[39mfit()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/statsmodels/discrete/discrete_model.py:475\u001b[0m, in \u001b[0;36mBinaryModel.__init__\u001b[0;34m(self, endog, exog, offset, check_rank, **kwargs)\u001b[0m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog, offset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_rank\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    473\u001b[0m     \u001b[38;5;66;03m# unconditional check, requires no extra kwargs added by subclasses\u001b[39;00m\n\u001b[1;32m    474\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_kwargs(kwargs)\n\u001b[0;32m--> 475\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_rank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_rank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m                     \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, MultinomialModel):\n\u001b[1;32m    478\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendog \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m&\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendog \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/statsmodels/discrete/discrete_model.py:185\u001b[0m, in \u001b[0;36mDiscreteModel.__init__\u001b[0;34m(self, endog, exog, check_rank, **kwargs)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog, check_rank\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_rank \u001b[38;5;241m=\u001b[39m check_rank\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraise_on_perfect_prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# keep for backwards compat\u001b[39;00m\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_extra \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/statsmodels/base/model.py:270\u001b[0m, in \u001b[0;36mLikelihoodModel.__init__\u001b[0;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 270\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialize()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/statsmodels/base/model.py:95\u001b[0m, in \u001b[0;36mModel.__init__\u001b[0;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m missing \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmissing\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     94\u001b[0m hasconst \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhasconst\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m---> 95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m                              \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_constant \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mk_constant\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mexog\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/statsmodels/base/model.py:135\u001b[0m, in \u001b[0;36mModel._handle_data\u001b[0;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_handle_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog, missing, hasconst, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 135\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mhandle_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;66;03m# kwargs arrays could have changed, easier to just attach here\u001b[39;00m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m kwargs:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/statsmodels/base/data.py:675\u001b[0m, in \u001b[0;36mhandle_data\u001b[0;34m(endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m    672\u001b[0m     exog \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(exog)\n\u001b[1;32m    674\u001b[0m klass \u001b[38;5;241m=\u001b[39m handle_data_class_factory(endog, exog)\n\u001b[0;32m--> 675\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mklass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m             \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/statsmodels/base/data.py:84\u001b[0m, in \u001b[0;36mModelData.__init__\u001b[0;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morig_endog \u001b[38;5;241m=\u001b[39m endog\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morig_exog \u001b[38;5;241m=\u001b[39m exog\n\u001b[0;32m---> 84\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendog, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_endog_exog\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconst_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_constant \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/statsmodels/base/data.py:509\u001b[0m, in \u001b[0;36mPandasData._convert_endog_exog\u001b[0;34m(self, endog, exog)\u001b[0m\n\u001b[1;32m    507\u001b[0m exog \u001b[38;5;241m=\u001b[39m exog \u001b[38;5;28;01mif\u001b[39;00m exog \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(exog)\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m endog\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m exog \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m exog\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[0;32m--> 509\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPandas data cast to numpy dtype of object. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    510\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCheck input data with np.asarray(data).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_convert_endog_exog(endog, exog)\n",
      "\u001b[0;31mValueError\u001b[0m: Pandas data cast to numpy dtype of object. Check input data with np.asarray(data)."
     ]
    }
   ],
   "source": [
    "# Model accuracy on the test set using the selected features\n",
    "X_test_rfe = X_test[selected_features]  # Use only the selected features for testing\n",
    "y_pred = model.predict(X_test_rfe)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Model Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Confusion Matrix and Classification Report\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Statistical Summary (using Statsmodels Logit for p-values)\n",
    "# Add constant to the features (intercept)\n",
    "X_train_const = sm.add_constant(X_train_rfe)  # Add intercept for statsmodels\n",
    "logit_model = sm.Logit(y_train, X_train_const)\n",
    "\n",
    "# Fit the model\n",
    "result = logit_model.fit()\n",
    "\n",
    "# Create a DataFrame with the coefficient values and their corresponding feature names\n",
    "feature_names = ['const'] + list(selected_features)  # Add 'const' for the intercept term\n",
    "coefficients_summary = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Coeff': round(result.params,3),\n",
    "    'Std Err': round(result.bse,3),\n",
    "    'z Value': round(result.tvalues,3),\n",
    "    'P-Value': round(result.pvalues,6),\n",
    "    'CI Lower': round(result.conf_int()[0],3),\n",
    "    'CI Upper': round(result.conf_int()[1],3)\n",
    "})\n",
    "\n",
    "# Print the summary\n",
    "print(\"\\nStatistical Summary from Statsmodels Logit with Feature Names:\")\n",
    "print(coefficients_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8610689-d4f7-4b48-88c6-89f484bf8252",
   "metadata": {},
   "source": [
    "**Analysis of Logistic Regression:**\n",
    "\n",
    "The model was trained on the training data and tested on the test data, achieving an overall accuracy of 66.56%, which is a solid starting point for predicting NBA game outcomes.\n",
    "\n",
    "The confusion matrix provides insight into the model's classification performance. It correctly predicted 700 wins (true positives) and 731 losses (true negatives). However, it misclassified 362 wins as losses (false negatives) and 357 losses as wins (false positives).\n",
    "\n",
    "Precision for predicting wins (label 1) is 0.67, meaning 67% of predicted wins were correct, while recall for wins is also 0.67, indicating that 67% of actual wins were identified by the model. Similarly, for losses (label 0), both precision and recall are 0.66. The F1-scores, which balance precision and recall, are 0.67 for wins and 0.66 for losses. These metrics highlight that the model performs comparably across both classes, demonstrating reliability in predicting outcomes based on the selected features, although there is room for improvement in handling closer classifications.\n",
    "\n",
    "Additionally, all p-values for the selected features were highly significant, each falling below the standard alpha threshold of 0.05. This indicates that the features used in the model were indeed relevant, contributing meaningfully to its performance. Overall, the model provides a strong foundation for future refinement and development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14e3c41-4d5f-4418-b997-184824684aa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3c87934-54ad-4e10-9343-d9a5f48420ca",
   "metadata": {},
   "source": [
    "Moving on to the Confusion Matrix... There are 2150 total boxscores in this dataset. There were 666 true negatives (model predicts a loss and the game was lossed for the .x team), so the model correctly predicted losses 666/2150 (find percentage) times There were 402 false negatives (model predicted a loss, but the game was won) so the model incorrectly predicted losses 402/2150 times There were 395 false positives (model predicts a win, and the game was lost) so the model incorrectly predicted wins 395/2150 times. There were 687 true positives (model predicts win, and the game was won), so the model correctly predicted wins 687/2150 (find %). There doesn't appear to be any noticiable biases. Since the model just tries to pick who will win the game, it makes sense it wouldnt be biased towards picking losses or wins.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93ff845-1f22-4586-9e6a-82943025438d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb0283d-a9a0-4874-bf3a-58c2ddbd6235",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "15b22474-c34d-472f-be91-549d1459bc36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy for game_number.x < 10: 0.6606\n",
      "\n",
      "Confusion Matrix for filtered data:\n",
      "[[602 314]\n",
      " [316 624]]\n",
      "\n",
      "Classification Report for filtered data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.66      0.66       916\n",
      "           1       0.67      0.66      0.66       940\n",
      "\n",
      "    accuracy                           0.66      1856\n",
      "   macro avg       0.66      0.66      0.66      1856\n",
      "weighted avg       0.66      0.66      0.66      1856\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kylebeedon/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Filter the test data for game_number.x < 22\n",
    "X_test_filtered = X_test[X_test['game_number.x'] >= 12]\n",
    "y_test_filtered = y_test[X_test['game_number.x'] >= 12]\n",
    "\n",
    "# Select only the features that were selected by RFE (the 10 selected features)\n",
    "X_test_filtered_rfe = X_test_filtered[selected_features]\n",
    "\n",
    "# Use the trained model to predict on the filtered data\n",
    "y_pred_filtered = model.predict(X_test_filtered_rfe)\n",
    "\n",
    "# Calculate the accuracy of the model on the filtered test data\n",
    "accuracy_filtered = accuracy_score(y_test_filtered, y_pred_filtered)\n",
    "print(f'Model Accuracy for game_number.x < 10: {accuracy_filtered:.4f}')\n",
    "\n",
    "# Optionally, print confusion matrix and classification report for the filtered data\n",
    "print(\"\\nConfusion Matrix for filtered data:\")\n",
    "print(confusion_matrix(y_test_filtered, y_pred_filtered))\n",
    "\n",
    "print(\"\\nClassification Report for filtered data:\")\n",
    "print(classification_report(y_test_filtered, y_pred_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "2e7b119d-fff3-4fa3-abee-81b7fc4c8adf",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (203267096.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[142], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    EXPLAIN YOURSELF -->\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "EXPLAIN YOURSELF --> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59825aa0-edaf-4abe-be9e-96c7ea80c3d0",
   "metadata": {},
   "source": [
    "Initial model accuracy of 0.636\n",
    "\n",
    "\n",
    "IDK About any of this: !!!!\n",
    "After running a simple logistic regression model with all of the features, we achieved an accuracy of 0.6274, which is a reasonable starting point. It is better than just picking the home team every time. We will look to improve this accuracy. I decided to use a train-test split as opposed to k-fold. I ran this, but got essentially the same accuracy, since it didn't improve the model, I used train-test because it is simpler.\n",
    "\n",
    "Moving on to the Confusion Matrix... There are 2150 total boxscores in this dataset. There were 666 true negatives (model predicts a loss and the game was lossed for the .x team), so the model correctly predicted losses 666/2150 (find percentage) times\n",
    "There were 402 false negatives (model predicted a loss, but the game was won) so the model incorrectly predicted losses 402/2150 times\n",
    "There were 395 false positives (model predicts a win, and the game was lost) so the model incorrectly predicted wins 395/2150 times. There were 687 true positives (model predicts win, and the game was won), so the model correctly predicted wins 687/2150 (find %). There doesn't appear to be any noticiable biases. Since the model just tries to pick who will win the game, it makes sense it wouldnt be biased towards picking losses or wins.\n",
    "\n",
    "It is interesting to look at the graphic interpretation of the features importance in the model. Some of the features don't seem to be statisitcally relevant, and others seem to have coefficients that don't make a lot of sense. It is in our best interest to implement feature selection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed08d3c-17e4-4468-9822-2a4fa162800e",
   "metadata": {},
   "source": [
    "### d) Random Forest\n",
    "After achieving some success with the logistic regression model, we next implement a RandomForestClassifier to explore whether we can improve model accuracy or achieve comparable results. This model will utilize 100 trees within the forest, with the top 11 features selected through RFE. The model will be trained on the training data and evaluated on the test data. Following this, we will analyze feature importance and compare model accuracies to gain further insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b971db8b-6056-4f47-8bda-59a413574ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    }
   ],
   "source": [
    "# Drop unwanted columns\n",
    "X_train = X_train.drop(columns=['game_number.x', 'game_number.y'], errors='ignore')\n",
    "X_test = X_test.drop(columns=['game_number.x', 'game_number.y'], errors='ignore')\n",
    "\n",
    "# Initialize Stratified K-Folds\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the parameter grid for Random Forest\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "# Initialize Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Perform Grid Search with Cross-Validation\n",
    "grid_search = RandomizedSearchCV(\n",
    "    RandomForestClassifier(),\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=50,  # Number of random combinations to try\n",
    "    cv=3,  # folds\n",
    "    verbose=2,\n",
    "    n_jobs=-1  # Use all available cores\n",
    ")\n",
    "\n",
    "# Fit the GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and best score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Cross-Validation Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "# Train the model with the best parameters on the full training set\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "best_rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on Test Data\n",
    "y_pred = best_rf_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nTest Set Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Confusion Matrix and Classification Report\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Feature Importance\n",
    "importances = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': best_rf_model.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Visualize Feature Importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "importances.plot(kind='barh', x='Feature', y='Importance', legend=False)\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Feature Importance Based on Optimized Random Forest Model')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e90b008-3a1a-4566-9a10-5e273daf33b5",
   "metadata": {},
   "source": [
    "**Analysis of Random Forest Classifier:**\n",
    "\n",
    "After running a standard Random Forest Classifier on the train-test split, the model initially showed a slight decrease in accuracy compared to the plain logistic regression model, achieving only 61.35% accuracy on the test data. To improve performance, I implemented 5-fold cross-validation, which evaluates the model's performance over multiple folds. This increased the test set accuracy to 63.86%, with a very low standard deviation of cross-validation accuracy, confirming the model's stability. To further enhance accuracy, I added a grid search to find the best combination of hyperparameters based on cross-validation results. This approach resulted in an improved test accuracy of **64.70%**, bringing it closer to the performance of the logistic regression model.\n",
    "\n",
    "Feature importance analysis revealed interesting insights into the key factors influencing game outcomes. The two most significant features were \"wins for X\" and \"wins for Y\" over the past 15 games, which makes sense as recent performance would likely be a strong indicator of future results. The four ratings were also highly influential, as they directly relate to how many points the teams have scored and allowed. Surprisingly, the \"defending offensive rebound percentage\" of the opposing team was an important feature, suggesting that how well a team defends offensive rebounds is crucial in determining outcomes. Other notable features included \"AST.x\" and \"home.x,\" along with statistics like \"TOV%\" and \"FG%\" for both teams. I was surprised by the low importance of the \"back_to_back\" feature, which specifically emphasizes fatigue, as it was the only feature that directly captured this aspect of gameplay.\n",
    "\n",
    "The confusion matrix and classification report showed that this model was moderately more accurate in predicting wins than in predicting losses.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960fdc1c-66aa-4f4d-a36a-8b9b6f3cb868",
   "metadata": {},
   "source": [
    "### e) Support Vector Classifier (SVM)\n",
    "\n",
    "After achieving similar successes with the Random Forest classifier, we aim to replicate or potentially improve our results using an SVM model. This model projects the n features into an n-dimensional space and finds the optimal hyperplane to separate classes. Similar to the Random Forest classifier, we will use a randomized search to identify the best hyperparameters and apply cross-validation to compare models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "bb10c077-8181-4885-9bd3-340f75e1fa6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n",
      "Best Cross-Validation Accuracy: 0.6356671381423857\n",
      "\n",
      "Test Set Accuracy: 0.6412\n",
      "\n",
      "Confusion Matrix:\n",
      "[[671 380]\n",
      " [381 689]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64      1051\n",
      "           1       0.64      0.64      0.64      1070\n",
      "\n",
      "    accuracy                           0.64      2121\n",
      "   macro avg       0.64      0.64      0.64      2121\n",
      "weighted avg       0.64      0.64      0.64      2121\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize Stratified K-Folds with fewer splits\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# Define a simpler parameter grid for SVM\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 0.01, 0.1],\n",
    "}\n",
    "\n",
    "# Initialize SVM model\n",
    "svc_model = SVC(random_state=42)\n",
    "\n",
    "# Perform RandomizedSearchCV with fewer iterations\n",
    "random_search = RandomizedSearchCV(\n",
    "    SVC(),\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=10,  # Fewer combinations to try\n",
    "    cv=2,  # Fewer folds\n",
    "    verbose=1,\n",
    "    n_jobs=-1  # Use all available cores\n",
    ")\n",
    "\n",
    "# Fit the RandomizedSearchCV\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Best score\n",
    "print(\"Best Cross-Validation Accuracy:\", random_search.best_score_)\n",
    "\n",
    "# Train the model with the best parameters on the full training set\n",
    "best_svc_model = random_search.best_estimator_\n",
    "best_svc_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on Test Data\n",
    "y_pred = best_svc_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nTest Set Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Confusion Matrix and Classification Report\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00b3ff4-aa24-47cb-a222-b033f6054062",
   "metadata": {},
   "source": [
    "**Analysis of Support Vector Classifier:**\n",
    "The runtime of the initial mdoel was very long, so I changed the number of cross validation splits to just 2, and simplified the paramater grid in comparision to the random forest classifeier. \n",
    "\n",
    "This model performed quite similarly to the logistic regression model. It had a higher accuracy on the test set than the random forest model\n",
    "With an accuracy on the test set of **66.19%**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb45908-2f98-4020-b499-ec67e93e861c",
   "metadata": {},
   "source": [
    "## **4. Predictions for Current Season**:\n",
    "The models use boxscore data from 2016 onward but do not include the current 2025 NBA season. Now, we can load in this data and test the accuracy using the three models. We should expect the results to be similar to the test accuracies of the previous models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "9fbff163-0e38-4d85-827a-2331966d7b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#current_season = pd.read_csv(\"DATA/box_scores_using_just_means/FINAL_current_szn.csv\") # Load in data from current season, as of 12/21/24\n",
    "current_season = pd.read_csv(\"DATA/box_scores_using_just_means/curr_szn15.csv\") # Load in data from current season, as of 12/21/24\n",
    "\n",
    "# Create X and y for current season\n",
    "X_curr = current_season\n",
    "X_curr = X_curr.drop(columns=['game_number.x'])\n",
    "# We want to use the same features from the RFE conducted earlier\n",
    "X_curr_rfe = X_curr[selected_features]\n",
    "\n",
    "y_curr = current_season['outcome.x']  # Target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b903e454-0cbd-4bdf-899f-d48f51d7727f",
   "metadata": {},
   "source": [
    "### a) Logistic Regression\n",
    "\n",
    "We start by observing how well our logisitic regression model fits the current season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "1728e40d-c44d-4dd6-a910-eaedf84741c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy of log reg model: 0.6425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kylebeedon/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "y_pred_curr = model.predict(X_curr_rfe)\n",
    "accuracy_curr = accuracy_score(y_curr, y_pred_curr)\n",
    "\n",
    "print(f'Model Accuracy of log reg model: {accuracy_curr:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cb7dff-371d-4d43-ace4-515e8b661907",
   "metadata": {},
   "source": [
    "### b) Random Forest\n",
    "\n",
    "We will now observe how the random forest model fairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "c0250bce-9312-4254-abb7-4aab69e54cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Accuracy on Current Season: 0.5881\n"
     ]
    }
   ],
   "source": [
    "# Ensure X_curr has only the columns used during training\n",
    "X_curr = X_curr.reindex(columns=X_train.columns, fill_value=0)\n",
    "X_curr = X_curr.drop(columns=['game_number.x'], errors='ignore')\n",
    "\n",
    "# Make predictions for the current season using the trained Random Forest model\n",
    "y_pred_RF = best_rf_model.predict(X_curr)\n",
    "\n",
    "# Compute the accuracy of the model on the current season\n",
    "accuracy_RF = accuracy_score(y_curr, y_pred_RF)\n",
    "\n",
    "# Print the accuracy\n",
    "print(f\"\\nModel Accuracy on Current Season: {accuracy_RF:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb80b57-a0f3-46c3-9197-3c531df86b72",
   "metadata": {},
   "source": [
    "### c) Support Vector Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "9bc89d54-e51a-4c25-8a9e-72c5bdcb85e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVM Model Accuracy on Current Season: 0.5881\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.2s\n",
      "[CV] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.8s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.8s\n",
      "[CV] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.8s\n",
      "[CV] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.6s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.5s\n",
      "[CV] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.1s\n",
      "[CV] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.3s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.6s\n",
      "[CV] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.3s\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.7s\n",
      "[CV] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.4s\n",
      "[CV] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   2.7s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.4s\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.2s\n",
      "[CV] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.6s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.7s\n",
      "[CV] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.2s\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.8s\n",
      "[CV] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.6s\n",
      "[CV] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.5s\n",
      "[CV] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.4s\n",
      "[CV] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.6s\n",
      "[CV] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.7s\n",
      "[CV] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   2.7s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.8s\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.7s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.5s\n",
      "[CV] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.4s\n",
      "[CV] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.6s\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.7s\n",
      "[CV] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.6s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.6s\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.8s\n",
      "[CV] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.2s\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.0s\n",
      "[CV] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.2s\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.6s\n",
      "[CV] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.7s\n",
      "[CV] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.7s\n",
      "[CV] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   2.6s\n",
      "[CV] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.3s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.6s\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.7s\n",
      "[CV] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.7s\n",
      "[CV] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.4s\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.2s\n",
      "[CV] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.4s\n",
      "[CV] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   2.6s\n",
      "[CV] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.1s\n",
      "[CV] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   2.7s\n",
      "[CV] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   2.6s\n",
      "[CV] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.7s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.6s\n",
      "[CV] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.6s\n",
      "[CV] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.2s\n",
      "[CV] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   2.7s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.4s\n",
      "[CV] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.7s\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.3s\n",
      "[CV] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   2.7s\n",
      "[CV] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.1s\n",
      "[CV] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.7s\n",
      "[CV] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.7s\n",
      "[CV] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.6s\n",
      "[CV] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.4s\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.8s\n",
      "[CV] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   2.6s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.3s\n",
      "[CV] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.3s\n",
      "[CV] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   2.6s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.7s\n",
      "[CV] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   2.7s\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.3s\n",
      "[CV] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.3s\n",
      "[CV] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.7s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   2.6s\n",
      "[CV] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.6s\n",
      "[CV] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.6s\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.6s\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.8s\n",
      "[CV] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.6s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.7s\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.7s\n",
      "[CV] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.8s\n",
      "[CV] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.4s\n",
      "[CV] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.6s\n",
      "[CV] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.7s\n",
      "[CV] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.5s\n",
      "[CV] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.8s\n",
      "[CV] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.7s\n",
      "[CV] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.3s\n",
      "[CV] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   2.6s\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.0s\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.7s\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.5s\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.6s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.3s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.6s\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.8s\n",
      "[CV] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.7s\n",
      "[CV] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   2.6s\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.4s\n",
      "[CV] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.6s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.7s\n",
      "[CV] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   2.7s\n",
      "[CV] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.6s\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.7s\n",
      "[CV] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.8s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.4s\n",
      "[CV] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.6s\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.9s\n",
      "[CV] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   2.6s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.5s\n",
      "[CV] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.3s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.0s\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.2s\n",
      "[CV] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.5s\n",
      "[CV] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.4s\n",
      "[CV] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.7s\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.7s\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.4s\n",
      "[CV] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.3s\n",
      "[CV] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.2s\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.0s\n",
      "[CV] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.4s\n",
      "[CV] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.7s\n",
      "[CV] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.6s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.7s\n",
      "[CV] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   2.7s\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.7s\n",
      "[CV] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.8s\n",
      "[CV] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.5s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.2s\n",
      "[CV] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.9s\n",
      "[CV] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.7s\n",
      "[CV] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.4s\n",
      "[CV] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.7s\n",
      "[CV] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.6s\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.7s\n",
      "[CV] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   2.6s\n",
      "[CV] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.2s\n",
      "[CV] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.6s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.6s\n",
      "[CV] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.3s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.5s\n",
      "[CV] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.4s\n",
      "[CV] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.2s\n",
      "[CV] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.7s\n",
      "[CV] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.7s\n",
      "[CV] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.7s\n",
      "[CV] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.7s\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.2s\n",
      "[CV] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.7s\n",
      "[CV] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.7s\n",
      "[CV] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.6s\n",
      "[CV] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.7s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.3s\n",
      "[CV] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.6s\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.1s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.8s\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.7s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.0s\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.7s\n",
      "[CV] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.5s\n",
      "[CV] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.4s\n",
      "[CV] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.7s\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.7s\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.4s\n",
      "[CV] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.3s\n",
      "[CV] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.3s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   2.7s\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.4s\n",
      "[CV] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.5s\n",
      "[CV] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   2.7s\n",
      "[CV] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.2s\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.8s\n",
      "[CV] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   2.6s\n",
      "[CV] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.5s\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.6s\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.6s\n",
      "[CV] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.3s\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.7s\n",
      "[CV] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.5s\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.7s\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.1s\n",
      "[CV] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.7s\n",
      "[CV] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.2s\n",
      "[CV] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   2.6s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.6s\n",
      "[CV] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.7s\n",
      "[CV] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.5s\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   2.7s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.5s\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.8s\n",
      "[CV] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.6s\n",
      "[CV] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.7s\n",
      "[CV] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.6s\n",
      "[CV] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.3s\n",
      "[CV] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.7s\n",
      "[CV] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.7s\n",
      "[CV] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.8s\n",
      "[CV] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.4s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.1s\n",
      "[CV] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.9s\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.8s\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.7s\n",
      "[CV] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.7s\n",
      "[CV] END class_weight=None, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.7s\n",
      "[CV] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.6s\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.7s\n",
      "[CV] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   2.6s\n",
      "[CV] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   2.6s\n",
      "[CV] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.3s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.7s\n",
      "[CV] END class_weight=balanced, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.5s\n",
      "[CV] END class_weight=None, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.7s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.2s\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.6s\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.8s\n",
      "[CV] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.7s\n",
      "[CV] END class_weight=balanced, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.7s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.7s\n",
      "[CV] END class_weight=balanced, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   2.7s\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.6s\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.8s\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.8s\n",
      "[CV] END class_weight=balanced, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END class_weight=None, max_depth=20, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END class_weight=None, max_depth=None, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.1s\n",
      "[CV] END class_weight=balanced, max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.6s\n",
      "[CV] END class_weight=None, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.8s\n"
     ]
    }
   ],
   "source": [
    "X_curr = X_curr.reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "# Make predictions for the current season using the trained SVM model\n",
    "y_pred_svc = best_svc_model.predict(X_curr)\n",
    "\n",
    "# Compute the accuracy of the SVM model on the current season\n",
    "accuracy_svc = accuracy_score(y_curr, y_pred_svc)\n",
    "\n",
    "# Print the accuracy\n",
    "print(f\"\\nSVM Model Accuracy on Current Season: {accuracy_svc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a60926f-0843-46ef-afb2-e571480806fb",
   "metadata": {},
   "source": [
    "### d) Analysis of models predicting current season\n",
    "\n",
    "All three models underperformed compared to their initial performance on the test set. Upon reflection, this is likely due to the fact that only around 30 games have been played per team so far, meaning that the first 15 games were trained on data from the previous season. This suggests the models were likely overfitted to outdated data. In hindsight, using previous season data was not the best approach. The only game that should incorporate previous season data is the first game of the current season for each team, as there is no other data available at that point.\n",
    "\n",
    "I will adjust my dataset to reflect this change and rerun the models, confident that this revision will improve their performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc34515-e5b6-4583-b67c-366392927644",
   "metadata": {},
   "source": [
    "## **5. Conclusion**:\n",
    "\n",
    "I WILL WRITE THE CONCLUSION AFTER I FIX THE ISSUES WITH THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5399fd3e-6f59-4b1e-a4b3-bcae9b5c6c5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0734911-897a-4691-8557-597f32a837df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aad37c72-66d5-41a8-8eab-90e50cce4650",
   "metadata": {},
   "source": [
    "## **Appendix:**\n",
    "Matthew Houde PROJECT_NAME:\n",
    "https://digitalcommons.bryant.edu/cgi/viewcontent.cgi?article=1000&context=honors_data_science\n",
    "\n",
    "Josh Weiner PROJECT_NAME:\n",
    "https://towardsdatascience.com/predicting-the-outcome-of-nba-games-with-machine-learning-a810bb768f20"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
